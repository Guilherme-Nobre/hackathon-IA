import os
import tempfile
import streamlit as st
from dotenv import load_dotenv

# === 0. Corrigir conflito de bibliotecas OpenMP ===
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# === 1. Imports LangChain ===
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import CharacterTextSplitter
from langchain_classic.chains import RetrievalQA
from langchain_community.document_loaders import PyMuPDFLoader

# === 2. Carregar vari√°veis de ambiente ===
load_dotenv()

# === 3. NOVO: Fun√ß√£o cacheada para processar V√ÅRIOS PDFs ===
@st.cache_resource
def create_rag_chain_from_pdfs(pdf_bytes_tuple): # MUDAN√áA: Recebe uma tupla de bytes
    """
    Processa V√ÅRIOS PDFs (em bytes), cria um RAG chain e o retorna.
    Fica em cache para evitar reprocessamento.
    """
    
    all_texts = [] # Lista para acumular textos de TODOS os PDFs

    # Definir o splitter uma vez, fora do loop
    splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=100
    )

    # MUDAN√áA: Iterar sobre os bytes de cada PDF enviado
    for pdf_bytes in pdf_bytes_tuple:
        # Usar um arquivo tempor√°rio para o PyMuPDFLoader (para cada PDF)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
            temp_file.write(pdf_bytes)
            file_path = temp_file.name

        try:
            # === 4. Leitura e divis√£o dos textos (por arquivo) ===
            loader = PyMuPDFLoader(file_path)
            docs = loader.load()
            
            texts = splitter.split_documents(docs)
            all_texts.extend(texts) # Adicionar os textos deste PDF √† lista total

        finally:
            # Limpar o arquivo tempor√°rio
            os.unlink(file_path)

    # === 5. Verifica√ß√£o (Ap√≥s processar TODOS os arquivos) ===
    if not all_texts:
        # Retorna None se nenhum texto foi extra√≠do de NENHUM PDF
        return None

    # === 6. Embeddings e vetorstore (Feito UMA VEZ com todos os textos) ===
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(all_texts, embeddings)

    # === 7. Cria√ß√£o do Retriever e Chain RAG ===
    retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 4}
    )

    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
    rag_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        return_source_documents=True
    )
    
    return rag_chain


# === 8. Interface Streamlit ===
st.set_page_config(page_title="Chat com M√∫ltiplos PDFs", layout="wide") # T√≠tulo atualizado
st.title("üìÑ Chat com M√∫ltiplos PDFs usando RAG e IA Generativa")

# MUDAN√áA: 'accept_multiple_files=True' e vari√°vel no plural 'pdf_files'
pdf_files = st.file_uploader("Envie um ou mais PDFs", type=["pdf"], accept_multiple_files=True)

if pdf_files: # MUDAN√áA: 'pdf_files' agora √© uma lista
    
    # MUDAN√áA: Ler os bytes de CADA arquivo e criar uma tupla (para o cache)
    pdf_bytes_list = [file.read() for file in pdf_files]
    pdf_bytes_tuple = tuple(pdf_bytes_list)
    
    # MUDAN√áA: Chamar a nova fun√ß√£o que aceita m√∫ltiplos arquivos
    rag_chain = create_rag_chain_from_pdfs(pdf_bytes_tuple)

    # === 9. Lidar com o caso de PDFs sem texto ===
    if rag_chain is None:
        st.error("Erro: N√£o foi poss√≠vel extrair texto dos PDFs. Verifique se os arquivos n√£o s√£o apenas imagens escaneadas ou se n√£o est√£o vazios.")
    else:
        # Mensagem de sucesso atualizada
        st.success(f"‚úÖ {len(pdf_files)} PDF(s) processados com sucesso! Agora voc√™ pode fazer perguntas sobre o conte√∫do combinado.")

        # === 10. Interface de perguntas (Permanece igual) ===
        user_question = st.text_input("‚ùì Pergunte algo sobre os documentos:")

        if user_question:
            with st.spinner("üîç Consultando o conte√∫do dos documentos..."):
                resposta = rag_chain.invoke({"query": user_question})

            st.markdown("### üß† Resposta:")
            st.write(resposta["result"])

            # Exibir fontes (opcional)
            with st.expander("üìö Fontes consultadas"):
                for i, doc in enumerate(resposta["source_documents"]):
                    st.markdown(f"**Trecho {i+1}:**")
                    st.write(doc.page_content)